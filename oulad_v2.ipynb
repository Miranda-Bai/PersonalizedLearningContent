{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msklearn\u001b[39;00m \n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msagemaker\u001b[39;00m \u001b[39mimport\u001b[39;00m get_execution_role\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import sklearn \n",
    "import numpy as np\n",
    "from sagemaker import get_execution_role\n",
    "import sagemaker\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
    "import datetime\n",
    "import time\n",
    "import tarfile\n",
    "import boto3\n",
    "import pandas as pd\n",
    "\n",
    "sm_boto3 = boto3.client(\"sagemaker\")\n",
    "sess = sagemaker.Session()\n",
    "region = sess.boto_session.region_name\n",
    "bucket = 'sagemaker-tutorial-s3-bucket-test' # Mention the created S3 bucket name here\n",
    "print(\"Using bucket \" + bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"OULAD_cleaned_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()\n",
    "# Run this cell to import the Data Wrangler widget to show automatic visualization and generate code to fix data quality issues\n",
    "\n",
    "import sagemaker_datawrangler\n",
    "\n",
    "# Display Pandas DataFrame to view the widget: df, display(df), df.sample()... \n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display how many rows and columns of the dataset\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show all rows of highest_education==\"HE Qualification\"\n",
    "HE_num = len(df[df.highest_education==\"HE Qualification\"])\n",
    "LowerA = len(df[df.highest_education==\"Lower Than A Level\"])\n",
    "LevelA= len(df[df.highest_education==\"A Level or Equivalent\"])\n",
    "PG_num=len(df[df.highest_education==\"Post Graduate Qualification\"])\n",
    "NoForm=len(df[df.highest_education==\"No Formal quals\"])\n",
    "\n",
    "print(HE_num)\n",
    "print(LowerA)\n",
    "print(LevelA)\n",
    "print(PG_num)\n",
    "print(NoForm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess \"highest_education\" column, Lower Than A Level:1,A Level or Equivalent:2,HE Qualification:3, postgraduate:4,no formal quals:0\n",
    "change={\"No Formal quals\":0, \"Lower Than A Level\":1, \"A Level or Equivalent\":2, \"HE Qualification\":3, \"Post Graduate Qualification\":4}\n",
    "df[\"highest_education\"] = df[\"highest_education\"] .map(change)\n",
    "\n",
    "# change code_module \n",
    "df[\"code_module\"] = df[\"code_module\"].map({\"AAA\":1, \"BBB\":2, \"CCC\":3, \"DDD\":4, \"EEE\":5, \"FFF\":6, \"GGG\":7})\n",
    "\n",
    "# change code_presentation\n",
    "df[\"code_presentation\"] = df[\"code_presentation\"].map({\"2013B\":1, \"2013J\":2, \"2014B\":3, \"2014J\":4})\n",
    "\n",
    "# change gender\n",
    "df[\"gender\"] = df[\"gender\"].map({\"M\":1, \"F\":0})\n",
    "\n",
    "# change age_band\n",
    "df[\"age_band\"] = df[\"age_band\"].map({\"0-35\":1, \"35-55\":2, \"55<=\":3})\n",
    "\n",
    "#change disability\n",
    "df[\"disability\"] = df[\"disability\"].map({\"N\":0, \"Y\":1})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete region and imd_band columns\n",
    "newdf = df.drop(columns=[\"region\", \"imd_band\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change final_result\n",
    "newdf[\"final_result\"] = newdf[\"final_result\"].map({\"Withdrawn\":0,  \"Fail\":1,  \"Pass\":2, \"Distinction\":3})\n",
    "# delete module_presentation column\n",
    "df=newdf.drop(columns=[\"module_presentation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete adjusted_mark and mark\n",
    "df = df.drop(columns=[\"adjusted_mark\",\"mark\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete Unnamed column\n",
    "df = df.drop(columns=[\"Unnamed: 0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dividing data to train data and test data\n",
    "train_data, test_data = np.split(df.sample(frac=1, random_state=1729), [int(0.7 * len(df))])\n",
    "print(train_data.shape, test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to csv file with combined tables\n",
    "pd.DataFrame(train_data).to_csv('oulad_train.csv')\n",
    "pd.DataFrame(test_data).to_csv('oulad_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# send data to S3. SageMaker will take training data from s3\n",
    "sk_prefix = \"sagemaker/personalizedcontent/OULADcontainer\"\n",
    "trainpath = sess.upload_data(\n",
    "    path=\"oulad_train.csv\", bucket=bucket, key_prefix=sk_prefix\n",
    ")\n",
    "\n",
    "testpath = sess.upload_data(\n",
    "    path=\"oulad_test.csv\", bucket=bucket, key_prefix=sk_prefix\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile oulad_script.py\n",
    "# create training script (top line has to be the first line in a cell)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_score, recall_score, f1_score, roc_curve, auc\n",
    "import sklearn\n",
    "import joblib\n",
    "import boto3\n",
    "import pathlib\n",
    "from io import StringIO \n",
    "import argparse\n",
    "import joblib\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# inference functions ---------------\n",
    "\n",
    "# def input_fn(request_body, request_content_type):\n",
    "#     print(request_body)\n",
    "#     print(request_content_type)\n",
    "#     if request_content_type == \"text/csv\":\n",
    "#         request_body = request_body.strip()\n",
    "#         try:\n",
    "#             df = pd.read_csv(StringIO(request_body), header=None)\n",
    "#             return df\n",
    "        \n",
    "#         except Exception as e:\n",
    "#             print(e)\n",
    "#     else:\n",
    "#         return \"\"\"Please use Content-Type = 'text/csv' and, send the request!!\"\"\" \n",
    " \n",
    "    \n",
    "def model_fn(model_dir):\n",
    "    clf = joblib.load(os.path.join(model_dir, \"model.joblib\"))\n",
    "    return clf\n",
    "\n",
    "# def predict_fn(input_data, model):\n",
    "#     if type(input_data) != str:\n",
    "#         prediction = model.predict(input_data)\n",
    "#         print(prediction)\n",
    "#         return prediction\n",
    "#     else:\n",
    "#         return input_data\n",
    "        \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    print(\"[INFO] Extracting arguments\")\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # hyperparameters sent by the client are passed as command-line arguments to the script.\n",
    "    parser.add_argument(\"--n_estimators\", type=int, default=100)\n",
    "    parser.add_argument(\"--random_state\", type=int, default=0)\n",
    "\n",
    "    # Data, model, and output directories\n",
    "    parser.add_argument(\"--model-dir\", type=str, default=os.environ.get(\"SM_MODEL_DIR\"))\n",
    "    parser.add_argument(\"--train\", type=str, default=os.environ.get(\"SM_CHANNEL_TRAIN\"))\n",
    "    parser.add_argument(\"--test\", type=str, default=os.environ.get(\"SM_CHANNEL_TEST\"))\n",
    "    parser.add_argument(\"--train-file\", type=str, default=\"oulad_train.csv\")\n",
    "    parser.add_argument(\"--test-file\", type=str, default=\"oulad_test.csv\")\n",
    "\n",
    "    args, _ = parser.parse_known_args()\n",
    "    \n",
    "    print(\"SKLearn Version: \", sklearn.__version__)\n",
    "    print(\"Joblib Version: \", joblib.__version__)\n",
    "\n",
    "    print(\"[INFO] Reading data\")\n",
    "    print()\n",
    "   \n",
    "    train_df = pd.read_csv(os.path.join(args.train, args.train_file))\n",
    "    test_df = pd.read_csv(os.path.join(args.test, args.test_file))\n",
    "    \n",
    "    features = list(train_df.columns)\n",
    "    label = \"final_result\"\n",
    "    \n",
    "    print(\"Building training and testing datasets\")\n",
    "    print()\n",
    "    \n",
    "    # change  \"total_score*weight\"  because target column has to be numerical\n",
    "    \n",
    "    X_train = train_df.drop( label, axis=1)\n",
    "    y_train = train_df[label]\n",
    "    X_test = test_df.drop(label, axis=1)\n",
    "    y_test = test_df[label]\n",
    "\n",
    "    print('Column order: ')\n",
    "    print(features)\n",
    "    print()\n",
    "    \n",
    "    print(\"Label column is: \",label)\n",
    "    print()\n",
    "    \n",
    "    print(\"Data Shape: \")\n",
    "    print()\n",
    "    print(\"---- SHAPE OF TRAINING DATA (70%) ----\")\n",
    "    print(X_train.shape)\n",
    "    print(y_train.shape)\n",
    "    print()\n",
    "    print(\"---- SHAPE OF TESTING DATA (30%) ----\")\n",
    "    print(X_test.shape)\n",
    "    print(y_test.shape)\n",
    "    print()\n",
    "    \n",
    "  \n",
    "    print(\"Training RandomForest Model.....\")\n",
    "    print()\n",
    "    model =  RandomForestClassifier(n_estimators=args.n_estimators, random_state=args.random_state, verbose = 3,n_jobs=-1)\n",
    "    # print(\"model is --------\")\n",
    "    # print(model)\n",
    "    # print(\"X_train, y_train:----------\")\n",
    "    # print(X_train)\n",
    "    # print(y_train)\n",
    "    model.fit(X_train, y_train)\n",
    "    print()\n",
    "    \n",
    "\n",
    "    model_path = os.path.join(args.model_dir, \"model.joblib\")\n",
    "    joblib.dump(model,model_path)\n",
    "    print(\"Model persisted at \" + model_path)\n",
    "    print()\n",
    "\n",
    "    \n",
    "    y_pred_test = model.predict(X_test)\n",
    "    test_acc = accuracy_score(y_test,y_pred_test)\n",
    "    test_rep = classification_report(y_test,y_pred_test)\n",
    "\n",
    "    print()\n",
    "    print(\"---- METRICS RESULTS FOR TESTING DATA ----\")\n",
    "    print()\n",
    "    print(\"Total Rows are: \", X_test.shape[0])\n",
    "    print('[TESTING] Model Accuracy is: ', test_acc)\n",
    "    print('[TESTING] Testing Report: ')\n",
    "    print(test_rep)\n",
    "    \n",
    "    # Tree Visualisation\n",
    "from sklearn.tree import export_graphviz\n",
    "# from IPython.display import Image\n",
    "import IPython.display\n",
    "import graphviz\n",
    "\n",
    "# Export the first three decision trees from the forest\n",
    "rf = model\n",
    "for i in range(3):\n",
    "    tree = rf.estimators_[i]\n",
    "    dot_data = export_graphviz(tree,\n",
    "                               feature_names=X_train.columns,  \n",
    "                               filled=True,  \n",
    "                               max_depth=2, \n",
    "                               impurity=False, \n",
    "                               proportion=True)\n",
    "    graph = graphviz.Source(dot_data)\n",
    "    print(\"******graph******\")\n",
    "    print(graph)\n",
    "    # Image(data=graph)\n",
    "    # IPython.display.Image(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python oulad_script.py --n_estimators 100 \\\n",
    "                   --random_state 0 \\\n",
    "                   --model-dir ./ \\\n",
    "                   --train ./ \\\n",
    "                   --test ./ \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tree Visualisation\n",
    "from sklearn.tree import export_graphviz\n",
    "from IPython.display import Image\n",
    "import graphviz\n",
    "\n",
    "# Export the first three decision trees from the forest\n",
    "rf = model\n",
    "for i in range(3):\n",
    "    tree = rf.estimators_[i]\n",
    "    dot_data = export_graphviz(tree,\n",
    "                               feature_names=X_train.columns,  \n",
    "                               filled=True,  \n",
    "                               max_depth=2, \n",
    "                               impurity=False, \n",
    "                               proportion=True)\n",
    "    graph = graphviz.Source(dot_data)\n",
    "    display(graph)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2 (v3.11.2:878ead1ac1, Feb  7 2023, 10:02:41) [Clang 13.0.0 (clang-1300.0.29.30)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
